# 深度学习在多变量时间序列插补中的应用：综述

## 1. 引言

多变量时间序列（MTS）数据常常由于传感器故障、系统环境不稳定、隐私问题等原因出现缺失值。这些缺失值破坏了时间序列的完整性，阻碍了有效的数据分析。传统的统计和机器学习插补方法在捕捉MTS数据中复杂的时序关系和变化模式方面存在不足。近年来，深度学习（DL）插补方法在提高损坏时间序列数据的质量方面取得了显著成功，并提升了下游任务的性能。本文综述了用于MTS数据的DL插补方法。

## 2. 基础知识与分类

### 2.1 MTSI问题定义背景

在一个完整的时间序列数据集[0, T]上，可以表示为D = {Xi, ti}N i=1，其中Xi = {x1:K,1:L} ∈ RK×L，ti = (t1, · · · , tL) ∈ [0, T]L。K是特征数量，L是时间序列的长度。在缺失数据的情况下，每个完整的时间序列可以分为观测部分和缺失部分，即Xi = {Xo i , Xm i }。用于编码缺失性的观测矩阵Mi = {m1:K,1:L}，其中mk,l = 0表示在时间戳tl处xk,l缺失，否则mk,l = 1。还会计算时间滞后矩阵δi = {δ1:K,1:L}。MTSI的目标是构建一个插补模型Mθ，以准确估计Xm中的缺失值。

### 2.2 缺失机制

缺失机制表示观测值与缺失数据概率之间的统计关系。根据鲁宾的理论，缺失机制分为三类：完全随机缺失（MCAR）、随机缺失（MAR）和非随机缺失（MNAR）。

## 3. 插补方法分类

作者提出了基于插补不确定性和神经网络架构的分类方法。

### 3.1 插补不确定性

根据插补方法是否能够产生反映插补值固有不确定性的不同结果，将插补方法分为预测性和生成性两类。

### 3.2 神经网络架构

讨论的模型包括基于RNN、CNN、GNN、注意力机制、VAE、GAN和扩散模型的模型。

## 4. 预测方法

预测插补方法为缺失部分预测确定性值，不考虑插补值的不确定性。这些方法通常采用基于重建的学习方式。

### 4.1 基于RNN的模型

RNN是建模序列数据的自然方式。例如，GRU-D旨在处理包含缺失值的时间序列，并通过时间衰减机制进行调节。

### 4.2 基于CNN的模型

CNN在时间序列分析中被广泛使用。TimesNet创新地结合快速傅里叶变换，将一维时间序列重构为二维格式。

### 4.3 基于GNN的模型

基于GNN的模型将时间序列视为图序列，并使用学习到的节点表示来重建缺失值。GRIN利用双向图循环神经网络。

### 4.4 基于注意力机制的模型

自注意力机制已被广泛用于建模序列数据。CDSA旨在通过从时间、位置和测量中联合学习来插补带有地理标签的时空数据。

## 5. 生成方法

生成插补方法基于VAE、GAN和扩散模型等生成模型。它们可以为缺失观测生成不同的输出，从而能够量化插补不确定性。

### 5.1 基于VAE的模型

VAE采用编码器-解码器结构来近似真实数据分布。GP-VAE在潜在空间中利用高斯过程先验来捕获时间动态。

### 5.2 基于GAN的模型

GAN通过生成器和判别器之间的极小化极大博弈进行对抗训练。GRUI-GAN是第一个用于时间序列数据插补的基于GAN的方法。

### 5.3 基于扩散模型的模型

扩散模型通过逐步添加然后反转噪声来捕获复杂的数据分布。CSDI是专门为MTSI设计的开创性扩散模型。

## 6. 实验评估与讨论

通过对不同类别的深度MTS插补方法进行实证实验，评估和分析了这些方法。结果显示，不同数据集上方法的性能各异，没有明确的胜者。在高缺失率的数据集上，深度学习插补方法明显优于统计方法。

## 7. 结论与未来方向

本文对深度学习模型在MTS插补中的应用进行了系统综述。作者指出了未来研究的潜在方向，包括处理MNAR上下文中的缺失数据、探索端到端学习范式、提高可扩展性以及将大型语言模型（LLMs）集成到MTSI中。

## GitHub仓库

论文相关代码和配置（包括定期更新的MTS插补论文列表）可在GitHub仓库中找到：[https://github.com/WenjieDu/Awesome Imputation](https://github.com/WenjieDu/Awesome Imputation)
