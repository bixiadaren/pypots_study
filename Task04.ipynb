{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7590ebb7-7982-47b2-906e-075efbb2537c",
   "metadata": {},
   "source": [
    "# Task04. 下游任务的端到端学习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a897acbc-beec-41a8-aa4a-933c5d35ee3a",
   "metadata": {},
   "source": [
    "# 1. 端到端学习的重要性\n",
    "\n",
    "### 在Task04中我们使用PyPOTS对自定义数据集进行了两阶段建模, 即在上游先对数据集中的缺失值进行插补, 然后对处理好的数据集进行下游任务建模. 同时, 我们也强调了缺失值本身也是数据集的特性, 数据的缺失模式可能携带了额外的信息来表征数据采集对象的状态, 而这些信息在两阶段处理中可能会丢失, 因为插补值是模型根据观测到的数据分布推测出来的, 插补后下游算法无法知道原数据中的缺失模式, 也就无法充分利用这部分信息来学习. 端到端学习则是使用一个模型直接接受包含缺失值的数据然后在特定任务上进行学习. 虽然在很多时候我们无法提前判断在某个时序数据集上是使用两阶段方法还是端到端方法能够取得更好的效果 (因为最终的效果涉及到很多方面, 包括但不限于模型自身的能力, 超参调优 等等), 但是端到端方法显然拥有更大的潜力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b452be00-8b10-49d9-b570-b53ff7978eb7",
   "metadata": {},
   "source": [
    "# 2. 使用BRITS直接在PhysioNet2012上进行分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1278070a-df35-43f5-a25a-51eb21bce761",
   "metadata": {},
   "source": [
    "### 2.1 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99150a70-41f9-421a-98be-2036c9b0b8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 23:27:30 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2025-05-10 23:27:30 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2025-05-10 23:27:30 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n",
      "2025-05-10 23:27:30 [INFO]: Loaded successfully!\n",
      "2025-05-10 23:27:33 [WARNING]: Note that physionet_2012 has sparse observations in the time series, hence we don't add additional missing values to the training dataset. \n",
      "2025-05-10 23:27:33 [INFO]: 23355 values masked out in the val set as ground truth, take 10.11% of the original observed values\n",
      "2025-05-10 23:27:33 [INFO]: 28874 values masked out in the test set as ground truth, take 10.06% of the original observed values\n",
      "2025-05-10 23:27:33 [INFO]: Total sample number: 3997\n",
      "2025-05-10 23:27:33 [INFO]: Training set size: 2557 (63.97%)\n",
      "2025-05-10 23:27:33 [INFO]: Validation set size: 640 (16.01%)\n",
      "2025-05-10 23:27:33 [INFO]: Test set size: 800 (20.02%)\n",
      "2025-05-10 23:27:33 [INFO]: Number of steps: 48\n",
      "2025-05-10 23:27:33 [INFO]: Number of features: 37\n",
      "2025-05-10 23:27:33 [INFO]: Train set missing rate: 79.71%\n",
      "2025-05-10 23:27:33 [INFO]: Validating set missing rate: 81.73%\n",
      "2025-05-10 23:27:33 [INFO]: Test set missing rate: 81.82%\n"
     ]
    }
   ],
   "source": [
    "from benchpots.datasets import preprocess_physionet2012\n",
    "\n",
    "physionet2012_dataset = preprocess_physionet2012(\n",
    "    subset=\"set-a\", \n",
    "    pattern=\"point\", \n",
    "    rate=0.1,\n",
    ")\n",
    "\n",
    "dataset_for_training = {\n",
    "    \"X\": physionet2012_dataset['train_X'],\n",
    "    \"y\": physionet2012_dataset['train_y'],\n",
    "}\n",
    "\n",
    "dataset_for_validating = {\n",
    "    \"X\": physionet2012_dataset['val_X'],\n",
    "    \"y\": physionet2012_dataset['val_y'],\n",
    "}\n",
    "\n",
    "dataset_for_testing = {\n",
    "    \"X\": physionet2012_dataset['test_X'],\n",
    "    \"y\": physionet2012_dataset['test_y'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfefd9b-dd42-455b-ab0a-e5a1a6fc4996",
   "metadata": {},
   "source": [
    "### 2.2 使用PyPOTS进行模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0bc709e-87e4-4b3b-a017-5501420b05bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/ml/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-05-10 23:27:35 [INFO]: No given device, using default device: cpu\n",
      "2025-05-10 23:27:35 [WARNING]: ‼️ saving_path not given. Model files and tensorboard file will not be saved.\n",
      "2025-05-10 23:27:35 [INFO]: Using customized CrossEntropy as the training loss function.\n",
      "2025-05-10 23:27:35 [INFO]: Using customized CrossEntropy as the validation metric function.\n",
      "2025-05-10 23:27:35 [INFO]: BRITS initialized with the given hyperparameters, the number of trainable parameters: 239,860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\n",
      "████████╗██╗███╗   ███╗███████╗    ███████╗███████╗██████╗ ██╗███████╗███████╗    █████╗ ██╗\n",
      "╚══██╔══╝██║████╗ ████║██╔════╝    ██╔════╝██╔════╝██╔══██╗██║██╔════╝██╔════╝   ██╔══██╗██║\n",
      "   ██║   ██║██╔████╔██║█████╗█████╗███████╗█████╗  ██████╔╝██║█████╗  ███████╗   ███████║██║\n",
      "   ██║   ██║██║╚██╔╝██║██╔══╝╚════╝╚════██║██╔══╝  ██╔══██╗██║██╔══╝  ╚════██║   ██╔══██║██║\n",
      "   ██║   ██║██║ ╚═╝ ██║███████╗    ███████║███████╗██║  ██║██║███████╗███████║██╗██║  ██║██║\n",
      "   ╚═╝   ╚═╝╚═╝     ╚═╝╚══════╝    ╚══════╝╚══════╝╚═╝  ╚═╝╚═╝╚══════╝╚══════╝╚═╝╚═╝  ╚═╝╚═╝\n",
      "ai4ts v0.0.2 - building AI for unified time-series analysis, https://time-series.ai \u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-10 23:27:55 [INFO]: Epoch 001 - training loss (CrossEntropy): 1.6684, validation CrossEntropy: 0.3586\n",
      "2025-05-10 23:28:10 [INFO]: Epoch 002 - training loss (CrossEntropy): 1.3455, validation CrossEntropy: 0.3242\n",
      "2025-05-10 23:28:25 [INFO]: Epoch 003 - training loss (CrossEntropy): 1.2476, validation CrossEntropy: 0.3078\n",
      "2025-05-10 23:28:41 [INFO]: Epoch 004 - training loss (CrossEntropy): 1.1837, validation CrossEntropy: 0.2944\n",
      "2025-05-10 23:28:55 [INFO]: Epoch 005 - training loss (CrossEntropy): 1.1343, validation CrossEntropy: 0.2714\n",
      "2025-05-10 23:29:08 [INFO]: Epoch 006 - training loss (CrossEntropy): 1.0961, validation CrossEntropy: 0.2644\n",
      "2025-05-10 23:29:21 [INFO]: Epoch 007 - training loss (CrossEntropy): 1.0771, validation CrossEntropy: 0.2475\n",
      "2025-05-10 23:29:34 [INFO]: Epoch 008 - training loss (CrossEntropy): 1.0568, validation CrossEntropy: 0.2329\n",
      "2025-05-10 23:29:46 [INFO]: Epoch 009 - training loss (CrossEntropy): 1.0158, validation CrossEntropy: 0.2196\n",
      "2025-05-10 23:29:59 [INFO]: Epoch 010 - training loss (CrossEntropy): 1.0153, validation CrossEntropy: 0.2646\n",
      "2025-05-10 23:30:13 [INFO]: Epoch 011 - training loss (CrossEntropy): 0.9913, validation CrossEntropy: 0.1832\n",
      "2025-05-10 23:30:26 [INFO]: Epoch 012 - training loss (CrossEntropy): 0.9705, validation CrossEntropy: 0.1704\n",
      "2025-05-10 23:30:38 [INFO]: Epoch 013 - training loss (CrossEntropy): 0.9379, validation CrossEntropy: 0.1508\n",
      "2025-05-10 23:30:52 [INFO]: Epoch 014 - training loss (CrossEntropy): 0.9184, validation CrossEntropy: 0.1403\n",
      "2025-05-10 23:31:05 [INFO]: Epoch 015 - training loss (CrossEntropy): 0.9037, validation CrossEntropy: 0.1266\n",
      "2025-05-10 23:31:18 [INFO]: Epoch 016 - training loss (CrossEntropy): 0.8769, validation CrossEntropy: 0.1092\n",
      "2025-05-10 23:31:31 [INFO]: Epoch 017 - training loss (CrossEntropy): 0.8754, validation CrossEntropy: 0.1021\n",
      "2025-05-10 23:31:44 [INFO]: Epoch 018 - training loss (CrossEntropy): 0.8570, validation CrossEntropy: 0.0884\n",
      "2025-05-10 23:31:57 [INFO]: Epoch 019 - training loss (CrossEntropy): 0.8363, validation CrossEntropy: 0.0705\n",
      "2025-05-10 23:32:10 [INFO]: Epoch 020 - training loss (CrossEntropy): 0.8076, validation CrossEntropy: 0.0493\n",
      "2025-05-10 23:32:10 [INFO]: Finished training. The best model is from epoch#20.\n"
     ]
    }
   ],
   "source": [
    "from pypots.classification import BRITS\n",
    "\n",
    "brits = BRITS(\n",
    "    n_steps=physionet2012_dataset['n_steps'],\n",
    "    n_features=physionet2012_dataset['n_features'],\n",
    "    n_classes=physionet2012_dataset[\"n_classes\"],\n",
    "    rnn_hidden_size=128,\n",
    "    epochs=20,\n",
    "    patience=5,\n",
    ")\n",
    "\n",
    "brits.fit(dataset_for_training, dataset_for_validating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f50e8f-2a3d-4010-a139-abf943320cd8",
   "metadata": {},
   "source": [
    "### 2.3 计算分类精度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc082c74-652f-42de-8a45-78fb32525a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRITS在测试集上的ROC-AUC为: 0.5823\n",
      "\n",
      "BRITS在测试集上的PR-AUC为: 0.4272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pypots.nn.functional.classification import calc_binary_classification_metrics\n",
    "\n",
    "brits_results = brits.predict(dataset_for_testing)\n",
    "brits_prediction = brits_results[\"classification\"]\n",
    "\n",
    "classification_metrics=calc_binary_classification_metrics(\n",
    "    brits_prediction, dataset_for_testing[\"y\"]\n",
    ")\n",
    "print(f\"BRITS在测试集上的ROC-AUC为: {classification_metrics['roc_auc']:.4f}\\n\")\n",
    "print(f\"BRITS在测试集上的PR-AUC为: {classification_metrics['pr_auc']:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00b472f-b8d5-4164-ba45-83704cb965b4",
   "metadata": {},
   "source": [
    "# 3. 阅读材料\n",
    "\n",
    "### Cao, W., Wang, D., Li, J., Zhou, H., Li, L., & Li, Y. (2018). [BRITS: Bidirectional Recurrent Imputation for Time Series](https://arxiv.org/abs/1805.10572). *NeurIPS 2018*.\n",
    "#### 推荐原因: 该文是时序插补领域绕不开的一篇文章. 该文在GRU-D和M-RNN模型的基础上做了改进, 效果获得明显提升. 文章被人工智能顶级会议NeurIPS 2018收录. 截止2025年5月Google Scholar上引用800+."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
